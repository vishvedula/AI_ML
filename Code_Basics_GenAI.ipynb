{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMs1QqmQuqyaCnJvRntkK0x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishvedula/AI_ML/blob/main/Code_Basics_GenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40VuMuCwhXeE"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pyngrok"
      ],
      "metadata": {
        "id": "SOKj8MXYjjrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2sNsmufdsJfwgVDdkH2GN70f2HH_7o7N1C3A7EN3mFhhmNpNQ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYPHRBQMjzKX",
        "outputId": "ee5c5a50-e32b-4a37-e423-4fbbc8427dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "\n",
        "st.title(\"Hello, Streamlit on Colab!\")\n",
        "st.write(\"This is a basic Streamlit app running on Google Colab.\")\n",
        "\n",
        "number = st.slider(\"Pick a number\", 0, 100)\n",
        "st.write(f\"You selected: {number}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF3Hlrdmj4B3",
        "outputId": "69006362-c74c-45b1-843a-ba937fe267dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup streamlit run app.py --server.port 8501 --server.enableCORS false --server.enableXsrfProtection false > logs.txt 2>&1 &"
      ],
      "metadata": {
        "id": "h1d9hpCLkARa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Start Streamlit in the background\n",
        "#!nohup streamlit run genai.py --server.port 8501 --server.enableCORS false --server.enableXsrfProtection false > logs.txt 2>&1 &\n",
        "\n",
        "# Expose Streamlit on port 8501\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Streamlit App URL:\", public_url)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnL_AqUAkGgB",
        "outputId": "1fb071fb-74fe-48d3-d7e0-fe48eb4a7966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit App URL: NgrokTunnel: \"https://d395-35-221-39-141.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "ejdDUdcAkjMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-generativeai"
      ],
      "metadata": {
        "id": "UkQ4r7bRmNWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q InstructorEmbedding\n",
        "!pip install -q transformers sentence-transformers"
      ],
      "metadata": {
        "id": "eYrahO1hpVlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U InstructorEmbedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLDfw1gxq6EO",
        "outputId": "73533132-a598-4f8a-937b-8c0b57f1b13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: InstructorEmbedding in /usr/local/lib/python3.11/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install HuggingFaceEmbeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zel2pZ6ntCsr",
        "outputId": "32d5a892-253c-4701-ca38-307c005dd20b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement HuggingFaceEmbeddings (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for HuggingFaceEmbeddings\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y InstructorEmbedding sentence-transformers langchain\n",
        "!pip install -U InstructorEmbedding sentence-transformers langchain\n"
      ],
      "metadata": {
        "id": "S4IAYfqGrfRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain-community"
      ],
      "metadata": {
        "id": "JpTDYBjcr003"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_google_genai"
      ],
      "metadata": {
        "id": "e5HP5aqLvz9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "#from langchain.llms import GooglePalm #deprecated\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings,HuggingFaceEmbeddings\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "import os\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()  # take environment variables from .env (especially openai api key)\n",
        "\n",
        "# Create Google Palm LLM model\n",
        "#llm = GooglePalm(google_api_key=os.getenv('GOOGLE_API_TOKEN'), temperature=0.1)\n",
        "#llm = GooglePalm(google_api_key='AIzaSyAYOAcj3yCc-98jlz1TJn0ALlMQXBzR_g4', temperature=0.1)\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key='AIzaSyAYOAcj3yCc-98jlz1TJn0ALlMQXBzR_g4')\n",
        "\n",
        "\n",
        "# # Initialize instructor embeddings using the Hugging Face model\n",
        "# instructor_embeddings = HuggingFaceInstructEmbeddings(\n",
        "#     model_name=\"hkunlp/instructor-large\",\n",
        "#     encode_kwargs={\"use_auth_token\": False}  # Disable token requirement\n",
        "# )\n",
        "\n",
        "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "\n",
        "instructor_embeddings = HuggingFaceEmbeddings(model_name=embedding_model)\n",
        "\n",
        "vectordb_file_path = \"faiss_index\"\n",
        "\n",
        "def create_vector_db():\n",
        "    # Load data from FAQ sheet\n",
        "    loader = CSVLoader(file_path='codebasics_faqs.csv',encoding=\"ISO-8859-1\", source_column=\"prompt\")\n",
        "    data = loader.load()\n",
        "\n",
        "    # Create a FAISS instance for vector database from 'data'\n",
        "    vectordb = FAISS.from_documents(documents=data,\n",
        "                                    embedding=instructor_embeddings)\n",
        "\n",
        "    # Save vector database locally\n",
        "    vectordb.save_local(vectordb_file_path)\n",
        "\n",
        "\n",
        "def get_qa_chain():\n",
        "    # Load the vector database from the local folder\n",
        "    vectordb = FAISS.load_local(vectordb_file_path, instructor_embeddings, allow_dangerous_deserialization=True  # Allow pickle loading\n",
        ")\n",
        "\n",
        "    # Create a retriever for querying the vector database\n",
        "    retriever = vectordb.as_retriever(score_threshold=0.7)\n",
        "\n",
        "    prompt_template = \"\"\"Given the following context and a question, generate an answer based on this context only.\n",
        "    In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
        "    If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
        "\n",
        "    CONTEXT: {context}\n",
        "\n",
        "    QUESTION: {question}\"\"\"\n",
        "\n",
        "    PROMPT = PromptTemplate(\n",
        "        template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        "    )\n",
        "\n",
        "    chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                        chain_type=\"stuff\",\n",
        "                                        retriever=retriever,\n",
        "                                        input_key=\"query\",\n",
        "                                        return_source_documents=True,\n",
        "                                        chain_type_kwargs={\"prompt\": PROMPT})\n",
        "\n",
        "    return chain\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    create_vector_db()\n",
        "    chain = get_qa_chain()\n",
        "    #print(chain.invoke(\"Do you have javascript course?\"))\n",
        "    print(chain.invoke(\"What is the duration of this bootcamp? How long will it last?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P4jGZRJmCSw",
        "outputId": "7513c2bf-e518-43c0-92fb-1fb166d5d885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'What is the duration of this bootcamp? How long will it last?', 'result': 'You can complete all courses in 3 months if you dedicate 2-3 hours per day.', 'source_documents': [Document(id='127e163c-703d-4123-9389-f7c4b50f38f7', metadata={'source': 'What is the duration of this bootcamp? How long will it last?', 'row': 8}, page_content='prompt: What is the duration of this bootcamp? How long will it last?\\nresponse: You can complete all courses in 3 months if you dedicate 2-3 hours per day.'), Document(id='cbb13bfe-ab91-47e6-90d7-480de35fb119', metadata={'source': 'Can I attend this bootcamp while working full time?', 'row': 9}, page_content='prompt: Can I attend this bootcamp while working full time?\\nresponse: Yes. This bootcamp is self-paced. You can learn on your own schedule.'), Document(id='8b05dbee-3e76-445d-bb04-f9a24580b1dc', metadata={'source': 'What if I don\\x92t like this bootcamp?', 'row': 6}, page_content='prompt: What if I don\\x92t like this bootcamp?\\nresponse: As promised we will give you a 100% refund based on the guidelines (Please refer to our course refund policy before enrolling).'), Document(id='834c64e0-870e-4dd1-a5ef-ec51893fe712', metadata={'source': 'Does this bootcamp have lifetime access?', 'row': 7}, page_content='prompt: Does this bootcamp have lifetime access?\\nresponse: Yes')]}\n"
          ]
        }
      ]
    }
  ]
}